{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "Autoregressive (AR) and Moving Average (MA) models are both used in time series analysis, but they have some key differences.\n",
    " \n",
    "\n",
    " An AR model predicts future values based on a linear combination of *past values* of the series. It assumes the current value is correlated with its own previous values. The order *p* means we use *p* previous lags. So, an AR(*p*) model can be represented as:\n",
    " \n",
    "\n",
    " $$y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + ... + \\phi_p y_{t-p} + \\epsilon_t$$\n",
    " \n",
    "\n",
    " where $c$ is a constant, $\\phi_1, ..., \\phi_p$ are the parameters of the model, and $\\epsilon_t$ is white noise.\n",
    " \n",
    "\n",
    " On the other hand, a MA model uses *past forecast errors* in a regression-like model. It suggests that the current value depends on recent errors. A MA model of order *q*, MA(*q*), is represented as:\n",
    " \n",
    "\n",
    " $$y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + ... + \\theta_q \\epsilon_{t-q}$$\n",
    " \n",
    "\n",
    " where $\\mu$ is the mean of the series, $\\theta_1, ..., \\theta_q$ are the parameters, and $\\epsilon_i$ terms are white noise error terms.\n",
    " \n",
    "\n",
    " In summary, AR uses past *values* of the time series. Whereas, MA uses past *errors*. Both try to capture different kinds of patterns from time series.\n",
    " \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "## (a)\n",
    " Model (1): $y_t = y_{t-1} + u_t$ is a Random Walk, it is also a special case of an AR(1) model, where the autoregressive parameter = 1.\n",
    " \n",
    "\n",
    " Model (2): $y_t = 0.5y_{t-1} + u_t$ is an AR(1) model.\n",
    " \n",
    "\n",
    " Model (3): $y_t = 0.8u_{t-1} + u_t$ is a MA(1) model.\n",
    " \n",
    "\n",
    "## (b)\n",
    " \n",
    "\n",
    " For Model (1) which is a random walk, the autocorrelation function (ACF) will show very slow decay. It theoretically stays at 1, for all lags, but will stay very high.\n",
    " \n",
    "\n",
    " For Model (2) which is an AR(1), the ACF will decay exponentially. The decay rate depends on the coefficient, 0.5 in this case.\n",
    " \n",
    "\n",
    " For Model (3), a MA(1), the ACF will have a significant autocorrelation at lag 1 (related to the 0.8 coefficient) and will be (close to) zero for all other lags.\n",
    " \n",
    "\n",
    "## (c)\n",
    " \n",
    "\n",
    " Model (1) is more likely to represent stock prices from a theoretical perspective because it is a random walk which is linked with the Efficient Market Hypothesis (EMH). EMH suggests that price changes are random and unpredictable.\n",
    " \n",
    "\n",
    " If model (2) or (3) truly represented how the stock market moved, we can potentially generate profit by forecasting future values. This because these models have parameters that suggest dependence on past values or past errors.\n",
    " \n",
    "\n",
    " ## (d)\n",
    " \n",
    "\n",
    " Model (1): $y_t = y_{t-1} + u_t$ shows, shocks are persistent and will not decay. if we substitute repeatedly, we get $y_t = y_0 + \\sum_{i=1}^{t} u_i$, implying current value is influenced by all previous shocks and initial value, and that, there is no decay, so shock at i=1 has same impact as i=t.\n",
    " \n",
    "\n",
    " Model (2): $y_t = 0.5y_{t-1} + u_t$ persistence of the shock decays exponentially. If we substitute repeatedly, we get\n",
    " $y_t = u_t + 0.5u_{t-1} + 0.5^2u_{t-2} + ... $ , so the influence of shocks decreases exponentially over time.\n",
    " \n",
    "\n",
    " Model (3): $y_t = 0.8u_{t-1} + u_t$, shocks only last for two time periods.\n",
    " \n",
    "\n",
    " $y_{t+1} = 0.8 u_t + u_{t+1}$.\n",
    " \n",
    "\n",
    " $y_{t+2} = 0.8u_{t+1} + u_{t+2}$.\n",
    " \n",
    "\n",
    " It's clear, impact of $u_t$ is visible until $t+1$. In MA(1) models like this one, shocks only have an effect of order of the model, in this case, it's 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "**(a)**\n",
    "\n",
    "The ACF is decaying, and the PACF has a significant spike at lag 1 and then becomes mostly insignificant. This pattern suggests an AR(1) model. The ACF does not cut off sharply, which would suggest a Moving Average process, and the partial autocorrelation function (PACF) does not decay, so higher AR models don't appear to be appropriate.\n",
    "\n",
    "**(b)**\n",
    "\n",
    "We can use the Ljung-Box Q\\* statistic to test if first 3 autocorrelations are jointly zero. The formula is:\n",
    "\n",
    "$$Q^* = T(T+2)\\sum_{k=1}^{m} \\frac{\\hat{\\rho_k^2}}{T-k}$$\n",
    "\n",
    "where *T* is the sample size, *m* is the number of lags being tested, and $\\hat{\\rho_k}$ is the sample autocorrelation at lag *k*. In our case, T = 100, m = 3, and we have the sample autocorrelations.\n",
    "\n",
    "$$ Q^* = 100(100+2) \\cdot (\\frac{0.420^2}{100-1} + \\frac{0.104^2}{100-2} + \\frac{0.032^2}{100-3})$$\n",
    "\n",
    "$$ Q^* = 10200 \\cdot (\\frac{0.1764}{99} + \\frac{0.010816}{98} + \\frac{0.001024}{97})$$\n",
    "\n",
    "$$ Q^* = 10200 \\cdot (0.0017818 + 0.0001104 + 0.0000106)$$\n",
    "\n",
    "$$ Q^* = 10200 \\cdot (0.0019028)$$\n",
    "\n",
    "$$ Q^* = 19.408$$\n",
    " The test statistic follows a $\\chi^2$ distribution with *m* degrees of freedom, so with m = 3 in our case.\n",
    " \n",
    "\n",
    " Using a chi-squared table, we can compare this to our alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code output: 7.814727903251179\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "alpha = 0.05  #Significance Level\n",
    "df = 3      #degrees of freedom\n",
    "\n",
    "critical_value = chi2.ppf(1 - alpha, df)\n",
    "print(f\"Code output: {critical_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Q\\* statistic (19.408) is much larger than the critical value (7.815 at 5% significance level, with 3 dof), we reject the null hypothesis that the first three autocorrelation coefficients are jointly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "An AR(2) model is stationary if the roots of its characteristic equation lie outside the unit circle, or, equivalently, if the inverse roots lie within the unit circle.\n",
    " \n",
    "\n",
    " The AR(2) model is $y_t = 0.803y_{t-1} + 0.682y_{t-2} + u_t$.\n",
    " \n",
    "\n",
    " We can rewrite that as\n",
    " $y_t - 0.803y_{t-1} - 0.682y_{t-2} = u_t$\n",
    " \n",
    "\n",
    " The characteristic equation is:\n",
    " \n",
    "\n",
    " $1 - 0.803z - 0.682z^2 = 0$.\n",
    " \n",
    "\n",
    "  Or,\n",
    " $z^2 -0.803z - 0.682 =0$ if it's changed to characteristic polynomial.\n",
    " \n",
    "\n",
    " We can use the quadratic formula to find the roots:\n",
    " $$z = \\frac{0.803 \\pm 1.83652}{2}$$\n",
    " $$z_1 = \\frac{0.803 + 1.83652}{2} = 1.31976$$\n",
    " \n",
    "\n",
    " $$z_2 = \\frac{0.803 - 1.83652}{2} = -0.51676$$\n",
    " We can say that since absolute values for the roots ($|z_1|$ ,$|z_2|$) are not both less than 1 ($1.31976 > 1$), model is not stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5\n",
    "\n",
    "To determine the \"optimal\" model order, we can use information criteria, such as the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). These criteria balance the goodness of fit (measured by the log-likelihood, related to the residual variance) with model complexity (number of parameters). Lower values of the information criteria indicate a better model.\n",
    "\n",
    "Since we are given $\\log(\\hat{\\sigma}^2)$, and not the actual log-likelihood, we need to calculate the criteria from it. The number of parameters is *p + q + 1* (including the constant term and the variance). The formulas are:\n",
    "\n",
    "$AIC = T \\cdot \\log(\\hat{\\sigma}^2) + 2k$\n",
    "\n",
    "$BIC = T \\cdot \\log(\\hat{\\sigma}^2) + k \\cdot \\log(T)$\n",
    "\n",
    "where *T* is the number of observations (200 here) and *k* is the number of parameters (*p + q + 1*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & AIC & BIC \\\\\n",
      "\\midrule\n",
      "0 & 0 & 188.400000 & 191.698317 \\\\\n",
      "\\cline{1-4}\n",
      "1 & 0 & 176.800000 & 183.396635 \\\\\n",
      "\\cline{1-4}\n",
      "0 & 1 & 184.400000 & 190.996635 \\\\\n",
      "\\cline{1-4}\n",
      "1 & 1 & 173.200000 & 183.094952 \\\\\n",
      "\\cline{1-4}\n",
      "2 & 1 & 168.200000 & 181.393269 \\\\\n",
      "\\cline{1-4}\n",
      "1 & 2 & 172.200000 & 185.393269 \\\\\n",
      "\\cline{1-4}\n",
      "2 & 2 & 167.800000 & 184.291587 \\\\\n",
      "\\cline{1-4}\n",
      "3 & 2 & 166.600000 & 186.389904 \\\\\n",
      "\\cline{1-4}\n",
      "2 & 3 & 168.400000 & 188.189904 \\\\\n",
      "\\cline{1-4}\n",
      "3 & 3 & 166.800000 & 189.888222 \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "log_sigma_sq = {\n",
    "    (0, 0): 0.932,\n",
    "    (1, 0): 0.864,\n",
    "    (0, 1): 0.902,\n",
    "    (1, 1): 0.836,\n",
    "    (2, 1): 0.801,\n",
    "    (1, 2): 0.821,\n",
    "    (2, 2): 0.789,\n",
    "    (3, 2): 0.773,\n",
    "    (2, 3): 0.782,\n",
    "    (3, 3): 0.764\n",
    "}\n",
    "\n",
    "T = 200\n",
    "\n",
    "def calculate_criteria(log_sigma_sq, p, q, T):\n",
    "  k = p + q + 1\n",
    "  aic = T * log_sigma_sq + 2 * k\n",
    "  bic = T * log_sigma_sq + k * np.log(T)\n",
    "  return aic, bic\n",
    "\n",
    "results = {}\n",
    "for (p, q), log_sigma in log_sigma_sq.items():\n",
    "    aic, bic = calculate_criteria(log_sigma, p, q, T)\n",
    "    results[(p, q)] = {'AIC': aic, 'BIC': bic}\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the lowest AIC is ARMA(3, 2). The model with the lowest BIC is ARMA(2, 1). BIC penalizes more number of parameters more, so it's natural to suggest less order. Choosing between (3,2) and (2,1) depends on how much parsimony we are going for. We are probably safer choosing (2,1) based on BIC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "\n",
    "## (a)\n",
    "\n",
    "The ARMA(1,1) model is given by:\n",
    "\n",
    "$y_t = 0.036 + 0.69y_{t-1} + 0.42u_{t-1} + u_t$\n",
    "\n",
    "We are given $y_{t-1} = 3.4$ and $u_{t-1} = -1.3$. We need to forecast $y_t$, $y_{t+1}$, and $y_{t+2}$. Crucially, since $u_t$ is a white noise process, its expected value is zero, i.e., $E[u_t] = 0$, $E[u_{t+1}] = 0$, etc.\n",
    "\n",
    "*   **Forecast for time t,  ($\\hat{y}_t$):**\n",
    "\n",
    "    $\\hat{y}_t = E[y_t | y_{t-1}, u_{t-1}] = 0.036 + 0.69y_{t-1} + 0.42u_{t-1} + E[u_t]$\n",
    "\n",
    "    $\\hat{y}_t = 0.036 + 0.69(3.4) + 0.42(-1.3) + 0$\n",
    "\n",
    "    $\\hat{y}_t = 0.036 + 2.346 - 0.546$\n",
    "\n",
    "    $\\hat{y}_t = 1.836$\n",
    "\n",
    "*   **Forecast for time t+1, ($\\hat{y}_{t+1}$):**\n",
    "\n",
    "    $\\hat{y}_{t+1} = E[y_{t+1} | y_{t-1}, u_{t-1}] = 0.036 + 0.69E[y_t] + 0.42E[u_t] + E[u_{t+1}]$\n",
    "\n",
    "    $\\hat{y}_{t+1} = 0.036 + 0.69\\hat{y}_t + 0.42(0) + 0$\n",
    "\n",
    "    $\\hat{y}_{t+1} = 0.036 + 0.69(1.836)$\n",
    "\n",
    "    $\\hat{y}_{t+1} = 0.036 + 1.26684$\n",
    "\n",
    "    $\\hat{y}_{t+1} = 1.30284$\n",
    "    $\\hat{y}_{t+1} \\approx 1.303$\n",
    "\n",
    "*   **Forecast for time t+2, ($\\hat{y}_{t+2}$):**\n",
    "\n",
    "    $\\hat{y}_{t+2} = E[y_{t+2} | y_{t-1}, u_{t-1}] = 0.036 + 0.69E[y_{t+1}] + 0.42E[u_{t+1}] + E[u_{t+2}]$\n",
    "\n",
    "    $\\hat{y}_{t+2} = 0.036 + 0.69\\hat{y}_{t+1} + 0 + 0$\n",
    "\n",
    "    $\\hat{y}_{t+2} = 0.036 + 0.69(1.30284)$\n",
    "\n",
    "    $\\hat{y}_{t+2} = 0.036 + 0.89896$\n",
    "\n",
    "    $\\hat{y}_{t+2} = 0.9349596 \\approx 0.935$\n",
    "\n",
    "## (b)\n",
    "\n",
    "The actual values are given as $y_t = -0.032$, $y_{t+1} = 0.961$, and $y_{t+2} = 0.203$.\n",
    "\n",
    "The forecast errors are:\n",
    "\n",
    "*   $e_t = y_t - \\hat{y}_t = -0.032 - 1.836 = -1.868$\n",
    "*   $e_{t+1} = y_{t+1} - \\hat{y}_{t+1} = 0.961 - 1.30284 = -0.34184$\n",
    "*   $e_{t+2} = y_{t+2} - \\hat{y}_{t+2} = 0.203 - 0.9349596= -0.7319596$\n",
    "\n",
    "The squared errors are:\n",
    "\n",
    "*   $e_t^2 = (-1.868)^2 = 3.489424$\n",
    "*   $e_{t+1}^2 = (-0.34184)^2 = 0.1168545856$\n",
    "*   $e_{t+2}^2 = (-0.7319596)^2 = 0.53576487$\n",
    "\n",
    "The Mean Squared Error (MSE) is the average of the squared errors:\n",
    "\n",
    "$MSE = \\frac{1}{3}(e_t^2 + e_{t+1}^2 + e_{t+2}^2)$\n",
    "\n",
    "$MSE = \\frac{1}{3}(3.489424 + 0.1168545856 + 0.53576487)$\n",
    "\n",
    "$MSE = \\frac{1}{3}(4.142043) \\approx 1.381$\n",
    "\n",
    "Therefore, the out-of-sample MSE is approximately 1.381."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the code in the attached notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      " & AIC & BIC \\\\\n",
      "(p,q) &  &  \\\\\n",
      "\\midrule\n",
      "(0, 0) & -115.208 & -109.397 \\\\\n",
      "(0, 1) & -113.644 & -104.929 \\\\\n",
      "(0, 2) & -112.109 & -100.488 \\\\\n",
      "(0, 3) & -110.785 & -96.258 \\\\\n",
      "(0, 4) & -108.791 & -91.360 \\\\\n",
      "(0, 5) & -107.107 & -86.770 \\\\\n",
      "(1, 0) & -113.693 & -104.977 \\\\\n",
      "(1, 1) & -111.815 & -100.194 \\\\\n",
      "(1, 2) & -110.383 & -95.857 \\\\\n",
      "(1, 3) & -111.576 & -94.144 \\\\\n",
      "(1, 4) & -109.622 & -89.285 \\\\\n",
      "(1, 5) & -111.240 & -87.997 \\\\\n",
      "(2, 0) & -112.046 & -100.424 \\\\\n",
      "(2, 1) & -111.848 & -97.321 \\\\\n",
      "(2, 2) & -114.239 & -96.807 \\\\\n",
      "(2, 3) & -118.812 & -98.475 \\\\\n",
      "(2, 4) & -122.934 & -99.692 \\\\\n",
      "(2, 5) & -120.995 & -94.848 \\\\\n",
      "(3, 0) & -110.396 & -95.869 \\\\\n",
      "(3, 1) & -108.411 & -90.979 \\\\\n",
      "(3, 2) & -106.407 & -86.070 \\\\\n",
      "(3, 3) & -114.588 & -91.346 \\\\\n",
      "(3, 4) & -120.951 & -94.803 \\\\\n",
      "(3, 5) & -125.365 & -96.312 \\\\\n",
      "(4, 0) & -108.415 & -90.984 \\\\\n",
      "(4, 1) & -106.418 & -86.081 \\\\\n",
      "(4, 2) & -114.794 & -91.552 \\\\\n",
      "(4, 3) & -114.163 & -88.016 \\\\\n",
      "(4, 4) & -124.268 & -95.215 \\\\\n",
      "(4, 5) & -124.862 & -92.904 \\\\\n",
      "(5, 0) & -106.572 & -86.235 \\\\\n",
      "(5, 1) & -110.048 & -86.806 \\\\\n",
      "(5, 2) & -114.155 & -88.007 \\\\\n",
      "(5, 3) & -122.516 & -93.463 \\\\\n",
      "(5, 4) & -121.037 & -89.079 \\\\\n",
      "(5, 5) & -121.079 & -86.216 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "Best model based on AIC: ARMA(3, 5)\n",
      "\n",
      "Best model based on BIC: ARMA(0, 0)\n",
      "\n",
      "--- Chosen Model Summary ---\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}          &   Return\\_FORD   & \\textbf{  No. Observations:  } &    130      \\\\\n",
      "\\textbf{Model:}                  &      ARIMA       & \\textbf{  Log Likelihood     } &   55.332    \\\\\n",
      "\\textbf{Date:}                   & Sun, 16 Feb 2025 & \\textbf{  AIC                } &  -106.665   \\\\\n",
      "\\textbf{Time:}                   &     17:31:18     & \\textbf{  BIC                } &  -100.930   \\\\\n",
      "\\textbf{Sample:}                 &    02-01-2002    & \\textbf{  HQIC               } &  -104.334   \\\\\n",
      "\\textbf{}                        &   - 11-01-2012   & \\textbf{                     } &             \\\\\n",
      "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{const}  &      -0.0008  &        0.014     &    -0.060  &         0.952        &       -0.028    &        0.026     \\\\\n",
      "\\textbf{sigma2} &       0.0250  &        0.001     &    20.284  &         0.000        &        0.023    &        0.027     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Ljung-Box (L1) (Q):}     & 0.51 & \\textbf{  Jarque-Bera (JB):  } & 616.15  \\\\\n",
      "\\textbf{Prob(Q):}                & 0.48 & \\textbf{  Prob(JB):          } &  0.00   \\\\\n",
      "\\textbf{Heteroskedasticity (H):} & 0.85 & \\textbf{  Skew:              } &  0.06   \\\\\n",
      "\\textbf{Prob(H) (two-sided):}    & 0.60 & \\textbf{  Kurtosis:          } & 13.66   \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{SARIMAX Results}\n",
      "\\end{center}\n",
      "\n",
      "Warnings: \\newline\n",
      " [1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "\n",
      "--- Forecasting Evaluation ---\n",
      "\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Model & MSE & MAE & MAPE & Correct Sign \\\\\n",
      "\\midrule\n",
      "Chosen ARMA(0,0) & 0.0 & 0.0 & 1.0 & 20.0 \\\\\n",
      "ARMA(1,1) & 0.0 & 0.0 & 1.0 & 20.0 \\\\\n",
      "Random Walk & 7.2 & 1.2 & 10.5 & 40.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.tsa.api as smt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # We get a lot of warnings from statsmodels, but this it should still work\n",
    "\n",
    "excel_file = pd.ExcelFile('../1/capm.xlsx')\n",
    "df = excel_file.parse('table')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "series1 = 'FORD'\n",
    "series2 = 'MICROSOFT'\n",
    "\n",
    "df[f'Return_{series1}'] = np.log(df[series1] / df[series1].shift(1))\n",
    "df[f'Return_{series2}'] = np.log(df[series2] / df[series2].shift(1))\n",
    "df = df.dropna()\n",
    "\n",
    "returns = df[f'Return_{series1}']\n",
    "\n",
    "# (a)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "smt.graphics.plot_acf(returns, lags=20, ax=axes[0])\n",
    "smt.graphics.plot_pacf(returns, lags=20, ax=axes[1], method='ywm')\n",
    "plt.show()\n",
    "\n",
    "# (b)\n",
    "\n",
    "def calculate_information_criteria(data, p, q):\n",
    "    model = ARIMA(data, order=(p, 0, q)).fit()\n",
    "    return model.aic, model.bic\n",
    "\n",
    "aic_values = {}\n",
    "bic_values = {}\n",
    "\n",
    "for p in range(6):\n",
    "    for q in range(6):\n",
    "        aic, bic = calculate_information_criteria(returns, p, q)\n",
    "        aic_values[(p, q)] = aic\n",
    "        bic_values[(p, q)] = bic\n",
    "\n",
    "aic_df = pd.DataFrame(list(aic_values.items()), columns=['(p,q)', 'AIC'])\n",
    "bic_df = pd.DataFrame(list(bic_values.items()), columns=['(p,q)', 'BIC'])\n",
    "\n",
    "print(pd.concat([aic_df.set_index('(p,q)'), bic_df.set_index('(p,q)')], axis=1).to_latex(float_format=\"%.3f\"))\n",
    "\n",
    "best_aic_model = min(aic_values, key=aic_values.get)\n",
    "best_bic_model = min(bic_values, key=bic_values.get)\n",
    "\n",
    "print(f\"\\nBest model based on AIC: ARMA{best_aic_model}\\n\")\n",
    "print(f\"Best model based on BIC: ARMA{best_bic_model}\")\n",
    "\n",
    "# (c)\n",
    "p_chosen = best_bic_model[0]\n",
    "q_chosen = best_bic_model[0]\n",
    "chosen_order = (p_chosen, q_chosen)\n",
    "\n",
    "train_data = returns[:-5]\n",
    "\n",
    "chosen_model = ARIMA(train_data, order=(chosen_order[0], 0, chosen_order[1])).fit()\n",
    "print(\"\\n--- Chosen Model Summary ---\")\n",
    "print(chosen_model.summary().as_latex())\n",
    "\n",
    "# (d)\n",
    "test_data = returns[-5:]\n",
    "holdout_prices = df[series1][-5:]\n",
    "\n",
    "# (d)(i)\n",
    "def arma_forecast(model, _, steps):\n",
    "    forecasts = model.forecast(steps=steps)\n",
    "    return forecasts\n",
    "\n",
    "chosen_model_forecasts = arma_forecast(chosen_model, train_data, len(test_data)) # Use chosen_model directly\n",
    "chosen_model_forecasts = pd.Series(chosen_model_forecasts, index=test_data.index) # Ensure index alignment\n",
    "\n",
    "\n",
    "# (d)(ii)\n",
    "arma11_model = ARIMA(train_data, order=(1, 0, 1)).fit()\n",
    "arma11_forecasts = arma_forecast(arma11_model, train_data, len(test_data))\n",
    "arma11_forecasts = pd.Series(arma11_forecasts, index=test_data.index) # Ensure index alignment\n",
    "\n",
    "\n",
    "# (d)(iii)\n",
    "drift = train_data.mean()\n",
    "\n",
    "last_log_price = np.log(df[series1].iloc[-6])\n",
    "rw_forecasts = [last_log_price + drift * (i + 1) for i in range(len(test_data))]\n",
    "rw_forecasts_returns = np.diff(rw_forecasts, prepend=np.log(train_data[-1]))\n",
    "rw_forecasts_returns = pd.Series(rw_forecasts_returns, index=test_data.index) # Ensure index alignment\n",
    "\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = mean_absolute_percentage_error(actual, predicted)\n",
    "\n",
    "    correct_sign = np.sum(np.sign(actual) == np.sign(predicted)) / len(actual) * 100\n",
    "\n",
    "    return mse, mae, mape, correct_sign\n",
    "\n",
    "\n",
    "chosen_mse, chosen_mae, chosen_mape, chosen_sign = calculate_metrics(test_data, chosen_model_forecasts)\n",
    "arma11_mse, arma11_mae, arma11_mape, arma11_sign = calculate_metrics(test_data, arma11_forecasts)\n",
    "rw_mse, rw_mae, rw_mape, rw_sign = calculate_metrics(test_data, rw_forecasts_returns)\n",
    "evaluation_metrics = pd.DataFrame({\n",
    "    'Model': ['Chosen ARMA(0,0)', 'ARMA(1,1)', 'Random Walk'],\n",
    "    'MSE': [chosen_mse, arma11_mse, rw_mse],\n",
    "    'MAE': [chosen_mae, arma11_mae, rw_mae],\n",
    "    'MAPE': [chosen_mape, arma11_mape, rw_mape],\n",
    "    'Correct Sign': [chosen_sign, arma11_sign, rw_sign]\n",
    "})\n",
    "\n",
    "print(\"\\n--- Forecasting Evaluation ---\\n\")\n",
    "print(evaluation_metrics.to_latex(index=False, float_format=\"%.1f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "## (a)\n",
    "\n",
    "Non-stationary variables are those whose statistical properties (mean, variance) change over time. Examples include economic series like GDP and inflation, which often exhibit trends, and stock prices or exchange rates, which might follow random walks. Demographic data and cumulative measures like rainfall also tend to be non-stationary. To address this, several techniques are used. Differencing (calculating the difference between consecutive observations) is common for removing trends. Transformations like taking the logarithm can stabilize the variance. Detrending, by fitting a regression model with time as a predictor, is suitable for deterministic trends. Decomposition separates the series into components, allowing separate modeling of the stationary residual, and filtering methods can also be applied.\n",
    "\n",
    "## (b)\n",
    "\n",
    "Testing for non-stationarity is crucial before building time series models. Regressing non-stationary variables on each other can lead to spurious regression, producing misleadingly significant results. Standard statistical tests assume stationarity; applying them to non-stationary data yields unreliable results. Model misspecification occurs when models designed for stationary data are used on non-stationary series, resulting in poor forecasts. The autocorrelation function (ACF) of non-stationary data can also be misinterpreted, leading to incorrect conclusions.\n",
    "\n",
    "## (c)\n",
    "Weak stationarity means the mean and variance are constant over time, and the autocovariance depends only on the lag. It's the most common definition, focusing on the first two moments. Strict stationarity is a stronger condition: the entire probabilistic behavior of the series is time-invariant. A deterministic trend is a non-random, predictable function of time, often a linear trend. A stochastic trend, like a random walk, is itself a random process where the current value depends on the previous value plus a random shock. Differencing is used to handle stochastic trends, whereas regression is used for deterministic trends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
